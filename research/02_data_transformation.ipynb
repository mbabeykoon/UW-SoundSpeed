{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'d:\\\\Nik\\\\UW-SoundSpeed'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from uwsoundspeed.constants import CONFIG_FILE_PATH, PARAMS_FILE_PATH\n",
    "from uwsoundspeed.utils.common import read_yaml, create_directories\n",
    "from pathlib import Path\n",
    "from typing import List, Dict, Any\n",
    "from dataclasses import dataclass\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class DataPreprocessingConfig:\n",
    "    root_dir: Path\n",
    "    data_path: Path\n",
    "    numerical_features: List[str]\n",
    "    # numerical_transformer: Dict[str, Any]\n",
    "    categorical_features: List[str]\n",
    "    # categorical_transformer: Dict[str, Any]\n",
    "    pca_n_components: float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class ConfigurationManager:\n",
    "    def __init__(self, config_filepath=CONFIG_FILE_PATH, params_filepath=PARAMS_FILE_PATH):\n",
    "        self.config = read_yaml(config_filepath)\n",
    "        self.params = read_yaml(params_filepath)\n",
    "\n",
    "        create_directories([self.config['artifacts_root']])\n",
    "\n",
    "    def get_data_preprocessing_config(self) -> DataPreprocessingConfig:\n",
    "        config = self.config['data_preprocessing']\n",
    "        params = self.params['preprocessing']\n",
    "\n",
    "        create_directories([Path(config['root_dir'])])\n",
    "\n",
    "        data_preprocessing_config = DataPreprocessingConfig(\n",
    "            root_dir=Path(config['root_dir']),\n",
    "            data_path=Path(config['data_path']),\n",
    "            numerical_features=params['numerical_features'],\n",
    "            # numerical_transformer=params['numerical_transformer'],\n",
    "            categorical_features=params['categorical_features'],\n",
    "            # categorical_transformer=params['categorical_transformer'],\n",
    "            pca_n_components=params['pca_n_components']\n",
    "        )\n",
    "\n",
    "        return data_preprocessing_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from box.exceptions import BoxValueError\n",
    "from uwsoundspeed.constants import *\n",
    "from uwsoundspeed.utils.common import read_yaml, create_directories\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "import pandas as pd\n",
    "import joblib\n",
    "import os\n",
    "\n",
    "class DataPreprocessor:\n",
    "    def __init__(self, config: DataPreprocessingConfig):\n",
    "        self.config = config\n",
    "        self.column_transformer = self._create_column_transformer()\n",
    "        self.pca = PCA(n_components=config.pca_n_components)\n",
    "\n",
    "    def _create_column_transformer(self):\n",
    "        # Setup the numerical transformer pipeline\n",
    "        numerical_pipeline = Pipeline([\n",
    "            ('imputer', SimpleImputer(strategy='median')),\n",
    "            ('scaler', StandardScaler())\n",
    "        ])\n",
    "\n",
    "        categorical_pipeline = Pipeline([\n",
    "            ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "            ('encoder', OneHotEncoder(handle_unknown='ignore'))\n",
    "        ])\n",
    "\n",
    "        # Combine into a ColumnTransformer\n",
    "        return ColumnTransformer(transformers=[\n",
    "            ('num', numerical_pipeline, self.config.numerical_features),\n",
    "            ('cat', categorical_pipeline, self.config.categorical_features),\n",
    "        ])\n",
    "\n",
    "    def preprocess_and_apply_pca(self):\n",
    "        # Read data\n",
    "        df = pd.read_pickle(self.config.data_path)\n",
    "\n",
    "        # Fit and transform the data with the pre-defined column transformer\n",
    "        X_transformed = self.column_transformer.fit_transform(df)\n",
    "\n",
    "        # Apply PCA with the pre-initialized PCA instance\n",
    "        X_pca = self.pca.fit_transform(X_transformed)\n",
    "\n",
    "        return X_pca\n",
    "\n",
    "    def save(self, subdir_name=\"preprocessor\"):\n",
    "        \"\"\"Saves the preprocessor and PCA components to the specified directory.\"\"\"\n",
    "        save_dir = os.path.join(self.config.root_dir, subdir_name)\n",
    "        os.makedirs(save_dir, exist_ok=True)\n",
    "        save_path = os.path.join(save_dir, \"preprocessor_and_pca.joblib\")\n",
    "        joblib.dump({'column_transformer': self.column_transformer, 'pca': self.pca}, save_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-03-19 00:57:00,865: INFO: common: YAML file: config\\config.yaml loaded successfully]\n",
      "[2024-03-19 00:57:00,870: INFO: common: YAML file: params.yaml loaded successfully]\n",
      "[2024-03-19 00:57:00,871: INFO: common: Directory created at: artifacts]\n",
      "[2024-03-19 00:57:00,873: INFO: common: Directory created at: artifacts\\data_transformation]\n"
     ]
    }
   ],
   "source": [
    "from uwsoundspeed.logging import logger\n",
    "try:\n",
    "    # Initialize ConfigurationManager and get preprocessing configuration\n",
    "    config_manager = ConfigurationManager()\n",
    "    data_preprocessing_config = config_manager.get_data_preprocessing_config()\n",
    "    data_preprocessor = DataPreprocessor(config=data_preprocessing_config)\n",
    "    \n",
    "    # Preprocess the data and apply PCA\n",
    "    # This method now internally reads the data, applies transformations, and PCA\n",
    "    X_pca = data_preprocessor.preprocess_and_apply_pca()\n",
    "\n",
    "    # Save the fitted preprocessor and PCA model for later use\n",
    "    data_preprocessor.save(subdir_name=\"data_preprocessor\")\n",
    "\n",
    "except Exception as e:\n",
    "    logger.error(\"An error occurred during data preprocessing\", exc_info=True)\n",
    "    raise e\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
