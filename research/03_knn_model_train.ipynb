{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'d:\\\\Resarch\\\\2024\\\\UW-SoundSpeed'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "from typing import List, Dict\n",
    "from uwsoundspeed.constants import CONFIG_FILE_PATH, PARAMS_FILE_PATH\n",
    "from uwsoundspeed.utils.common import read_yaml, create_directories\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class PreprocessingConfig:\n",
    "    numerical_features: List[str]\n",
    "    numerical_transformer: Dict[str, any]\n",
    "    categorical_features: List[str]\n",
    "    categorical_transformer: Dict[str, any]\n",
    "\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class PrepareDataConfig:\n",
    "    root_dir: Path\n",
    "    data_file_path: Path\n",
    "    preprocessing: PreprocessingConfig\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class PCAConfig:\n",
    "    n_components: float\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class ModelConfig:\n",
    "    KNeighborsRegressor: Dict[str, List[int]]\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class GridSearchConfig:\n",
    "    cv: int\n",
    "    scoring: str\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class TrainTestSplitConfig:\n",
    "    test_size: float\n",
    "    random_state: int\n",
    "\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class PrepareBaseModelConfig:\n",
    "    root_dir: Path\n",
    "    data_file_path: Path\n",
    "    preprocessing: PreprocessingConfig\n",
    "    pca: PCAConfig\n",
    "    model: ModelConfig\n",
    "    grid_search: GridSearchConfig\n",
    "    train_test_split: TrainTestSplitConfig\n",
    "    knn_model_path: Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class ConfigurationManager:\n",
    "    def __init__(\n",
    "        self, \n",
    "        config_filepath = CONFIG_FILE_PATH ,\n",
    "        params_filepath = PARAMS_FILE_PATH):\n",
    "        self.config = read_yaml(config_filepath)\n",
    "        self.params = read_yaml(params_filepath)\n",
    "        create_directories([self.config.artifacts_root])\n",
    "\n",
    "    def get_preprocessing_config(self) -> PreprocessingConfig:\n",
    "        config = self.params.preprocessing \n",
    "        return PreprocessingConfig(\n",
    "            numerical_features=config['numerical_features'],\n",
    "            numerical_transformer=config['numerical_transformer'],\n",
    "            categorical_features=config['categorical_features'],\n",
    "            categorical_transformer=config['categorical_transformer']\n",
    "        )\n",
    "    \n",
    "    def get_pca_config(self) -> PCAConfig:\n",
    "        pca = self.params.pca\n",
    "        return PCAConfig(n_components=pca['n_components'])\n",
    "\n",
    "    def get_model_config(self) -> ModelConfig:\n",
    "        model = self.params.model\n",
    "        return ModelConfig(KNeighborsRegressor=model['KNeighborsRegressor'])\n",
    "\n",
    "    def get_grid_search_config(self) -> GridSearchConfig:\n",
    "        grid_search = self.params.grid_search\n",
    "        return GridSearchConfig(cv=grid_search['cv'], scoring=grid_search['scoring'])\n",
    "\n",
    "    def get_train_test_split_config(self) -> TrainTestSplitConfig:\n",
    "        split_config = self.params.train_test_split\n",
    "        return TrainTestSplitConfig(test_size=split_config['test_size'], random_state=split_config['random_state'])\n",
    "    \n",
    "\n",
    "    def get_prepare_base_model_config(self) -> PrepareBaseModelConfig:\n",
    "    # Assuming 'prepare_knn_model' contains all necessary configuration paths and settings\n",
    "        config = self.config['prepare_knn_model']\n",
    "        \n",
    "        # Create necessary directories specified in the configuration\n",
    "        create_directories([Path(config['root_dir'])])\n",
    "\n",
    "        # Construct and return the PrepareBaseModelConfig object with appropriate paths and settings\n",
    "        prepare_base_model_config = PrepareBaseModelConfig(\n",
    "            root_dir=Path(config['root_dir']),\n",
    "            data_file_path=Path(config['data_file_path']),\n",
    "            preprocessing=self.get_preprocessing_config(),\n",
    "            pca=self.get_pca_config(),\n",
    "            model=self.get_model_config(),\n",
    "            grid_search=self.get_grid_search_config(),\n",
    "            train_test_split=self.get_train_test_split_config(),\n",
    "            knn_model_path=Path(config['knn_model_path'])\n",
    "        )\n",
    "\n",
    "        return prepare_base_model_config\n",
    "    \n",
    "    # def get_prepare_base_model_config(self) -> PrepareBaseModelConfig:\n",
    "        \n",
    "    #     return PrepareBaseModelConfig(\n",
    "    #         root_dir=self.config.prepare_knn_model['root_dir'],\n",
    "    #         data_file_path=self.config.prepare_knn_model['data_file_path'],\n",
    "    #         preprocessing=self.get_preprocessing_config(),\n",
    "    #         pca=self.get_pca_config(),\n",
    "    #         model=self.get_model_config(),\n",
    "    #         grid_search=self.get_grid_search_config(),\n",
    "    #         train_test_split=self.get_train_test_split_config(),\n",
    "    #         knn_model_path=self.config.prepare_knn_model['knn_model_path'],  \n",
    "    #     )\n",
    "    \n",
    "    # def print_all_configs(self):\n",
    "    #     print(\"Preprocessing Configuration:\")\n",
    "    #     preprocessing_config = self.get_preprocessing_config()\n",
    "    #     print(f\"  Numerical Features: {preprocessing_config.numerical_features}\")\n",
    "    #     print(f\"  Numerical Transformer: {preprocessing_config.numerical_transformer}\")\n",
    "    #     print(f\"  Categorical Features: {preprocessing_config.categorical_features}\")\n",
    "    #     print(f\"  Categorical Transformer: {preprocessing_config.categorical_transformer}\\n\")\n",
    "        \n",
    "    #     print(\"PCA Configuration:\")\n",
    "    #     pca_config = self.get_pca_config()\n",
    "    #     print(f\"  N Components: {pca_config.n_components}\\n\")\n",
    "        \n",
    "    #     print(\"Model Configuration:\")\n",
    "    #     model_config = self.get_model_config()\n",
    "    #     for model_name, params in model_config.__dict__.items():\n",
    "    #         print(f\"  {model_name}: {params}\")\n",
    "    #     print(\"\\n\")\n",
    "        \n",
    "    #     print(\"Grid Search Configuration:\")\n",
    "    #     grid_search_config = self.get_grid_search_config()\n",
    "    #     print(f\"  CV: {grid_search_config.cv}\")\n",
    "    #     print(f\"  Scoring: {grid_search_config.scoring}\\n\")\n",
    "        \n",
    "    #     print(\"Train Test Split Configuration:\")\n",
    "    #     split_config = self.get_train_test_split_config()\n",
    "    #     print(f\"  Test Size: {split_config.test_size}\")\n",
    "    #     print(f\"  Random State: {split_config.random_state}\\n\")\n",
    "        \n",
    "    #     print(\"KNN Model Path (if applicable):\")\n",
    "    #     base_model_config = self.get_prepare_base_model_config()\n",
    "    #     print(f\"  KNN Model Path: {base_model_config.knn_model_path}\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-03-11 21:37:09,733: INFO: common: YAML file: config\\config.yaml loaded successfully]\n",
      "[2024-03-11 21:37:09,739: INFO: common: YAML file: params.yaml loaded successfully]\n",
      "[2024-03-11 21:37:09,742: INFO: common: Directory created at: artifacts]\n",
      "Preprocessing Configuration:\n",
      "  Numerical Features: ['Lat', 'Lon', 'SSS', 'SST', 'z']\n",
      "  Numerical Transformer: {'imputer_strategy': 'median', 'scaler': 'StandardScaler'}\n",
      "  Categorical Features: ['Month']\n",
      "  Categorical Transformer: {'imputer_strategy': 'most_frequent', 'onehot': 'OneHotEncoder', 'handle_unknown': 'ignore'}\n",
      "\n",
      "PCA Configuration:\n",
      "  N Components: 0.9\n",
      "\n",
      "Model Configuration:\n",
      "  KNeighborsRegressor: {'n_neighbors': [1, 2, 3, 4, 5]}\n",
      "\n",
      "\n",
      "Grid Search Configuration:\n",
      "  CV: 2\n",
      "  Scoring: neg_mean_squared_error\n",
      "\n",
      "Train Test Split Configuration:\n",
      "  Test Size: 0.2\n",
      "  Random State: 42\n",
      "\n",
      "KNN Model Path (if applicable):\n",
      "  KNN Model Path: artifacts/prepare_knn_model/knn_model.h5\n",
      "\n"
     ]
    }
   ],
   "source": [
    "config_manager = ConfigurationManager(config_filepath=CONFIG_FILE_PATH, params_filepath=PARAMS_FILE_PATH)\n",
    "config_manager.print_all_configs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import joblib\n",
    "from uwsoundspeed import logger\n",
    "\n",
    "class KnnModelTrain:\n",
    "\n",
    "    def __init__(self, config_manager):\n",
    "        self.config_manager = config_manager  # Correct initialization\n",
    "        self.config = self.config_manager.get_prepare_base_model_config()\n",
    "        self.data = None\n",
    "        self.preprocessor = None\n",
    "        self.best_model = None   \n",
    "        \n",
    "    def load_data(self):\n",
    "        base_model_config = self.config_manager.get_prepare_base_model_config()\n",
    "        self.data = pd.read_pickle(base_model_config.data_file_path)\n",
    "        logger.info(f\"Data loaded successfully from {base_model_config.data_file_path}.\")\n",
    "\n",
    "    def prepare_pipeline(self):\n",
    "        prep_config = self.config_manager.get_preprocessing_config()\n",
    "        pca_config = self.config_manager.get_pca_config()\n",
    "        model_config = self.config_manager.get_model_config().KNeighborsRegressor  \n",
    "\n",
    "\n",
    "        # Numerical features pipeline\n",
    "        numerical_pipeline = Pipeline([\n",
    "            ('imputer', SimpleImputer(strategy=prep_config.numerical_transformer['imputer_strategy'])),\n",
    "            ('scaler', StandardScaler())\n",
    "        ])\n",
    "\n",
    "        # Categorical features pipeline\n",
    "        categorical_pipeline = Pipeline([\n",
    "            ('imputer', SimpleImputer(strategy=prep_config.categorical_transformer['imputer_strategy'])),\n",
    "            ('onehot', OneHotEncoder(handle_unknown=prep_config.categorical_transformer['handle_unknown']))\n",
    "        ])\n",
    "\n",
    "        # Combined preprocessing pipeline\n",
    "        preprocessor = ColumnTransformer(transformers=[\n",
    "            ('num', numerical_pipeline, prep_config.numerical_features),\n",
    "            ('cat', categorical_pipeline, prep_config.categorical_features)\n",
    "        ])\n",
    "\n",
    "        # Full pipeline with PCA and KNeighborsRegressor placeholder\n",
    "        self.pipeline = Pipeline(steps=[\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('pca', PCA(n_components=pca_config.n_components)),\n",
    "        ('knn', KNeighborsRegressor(n_neighbors=model_config['n_neighbors'][0]))  \n",
    "        ])\n",
    "\n",
    "\n",
    "        \n",
    "    def train_test_split(self):\n",
    "    # Retrieve train-test split configuration using the config_manager\n",
    "        split_config = self.config_manager.get_train_test_split_config()\n",
    "        X = self.data.drop('c', axis=1)  # Make sure 'target_column' matches your actual target column name\n",
    "        y = self.data['c']\n",
    "        self.X_train, self.X_test, self.y_train, self.y_test = train_test_split(\n",
    "            X, y, test_size=split_config.test_size, random_state=split_config.random_state\n",
    "        )\n",
    "        logger.info(\"Train-test split completed.\")\n",
    "\n",
    "\n",
    "    def train_and_evaluate(self):\n",
    "\n",
    "        model_config = self.config_manager.get_model_config().KNeighborsRegressor\n",
    "        grid_search_config = self.config_manager.get_grid_search_config()\n",
    "\n",
    "  \n",
    "        \n",
    "        grid_search = GridSearchCV(\n",
    "            self.pipeline,\n",
    "            param_grid={'knn__n_neighbors': model_config['n_neighbors']},\n",
    "            cv=grid_search_config.cv,\n",
    "            scoring=grid_search_config.scoring,\n",
    "            verbose=1\n",
    "        )\n",
    "\n",
    "        grid_search.fit(self.X_train, self.y_train)\n",
    "        self.best_model = grid_search.best_estimator_\n",
    "\n",
    "        y_pred = self.best_model.predict(self.X_test)\n",
    "        logger.info(f\"R^2: {r2_score(self.y_test, y_pred)}\")\n",
    "        logger.info(f\"RMSE: {mean_squared_error(self.y_test, y_pred, squared=False)}\")\n",
    "\n",
    "    def save_model(self):\n",
    "        knn_model_path = self.config_manager.get_prepare_base_model_config().knn_model_path\n",
    "        joblib.dump(self.best_model, knn_model_path)\n",
    "        logger.info(f\"Best KNN model saved to {knn_model_path}\")\n",
    "\n",
    "\n",
    "    # def train_and_evaluate(self):\n",
    "    #     model_config = self.config.get_model_config().KNeighborsRegressor\n",
    "    #     grid_search_config = self.config.get_grid_search_config()\n",
    "        \n",
    "    #     grid_search = GridSearchCV(\n",
    "    #         self.pipeline,\n",
    "    #         param_grid={'knn__n_neighbors': model_config['n_neighbors']},\n",
    "    #         cv=grid_search_config.cv,\n",
    "    #         scoring=grid_search_config.scoring,\n",
    "    #         verbose=1\n",
    "    #     )\n",
    "\n",
    "    #     grid_search.fit(self.X_train, self.y_train)\n",
    "    #     self.best_model = grid_search.best_estimator_\n",
    "\n",
    "    #     y_pred = self.best_model.predict(self.X_test)\n",
    "    #     print(f\"R^2: {r2_score(self.y_test, y_pred)}\")\n",
    "    #     print(f\"RMSE: {mean_squared_error(self.y_test, y_pred, squared=False)}\")\n",
    "        \n",
    "\n",
    "            # def train_test_split(self):\n",
    "    #     split_config = self.config.get_train_test_split_config()\n",
    "    #     X = self.data.drop('c', axis=1)  \n",
    "    #     y = self.data['c']  \n",
    "    #     self.X_train, self.X_test, self.y_train, self.y_test = train_test_split(\n",
    "    #         X, y, test_size=split_config.test_size, random_state=split_config.random_state\n",
    "    #     )\n",
    "        \n",
    "\n",
    "    # def save_model(self):\n",
    "    #     knn_model_path = self.config.get_prepare_base_model_config().knn_model_path\n",
    "    #     joblib.dump(self.best_model, knn_model_path)\n",
    "    #     print(f\"Best KNN model saved to {knn_model_path}\")\n",
    "\n",
    "    # def run(self):\n",
    "    #     self.load_data()\n",
    "    #     self.prepare_pipeline()\n",
    "    #     self.train_test_split()\n",
    "    #     self.train_and_evaluate()\n",
    "    #     self.save_model()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-03-12 02:03:45,723: INFO: common: YAML file: config\\config.yaml loaded successfully]\n",
      "[2024-03-12 02:03:45,818: INFO: common: YAML file: params.yaml loaded successfully]\n",
      "[2024-03-12 02:03:45,824: INFO: common: Directory created at: artifacts]\n",
      "[2024-03-12 02:03:45,828: INFO: common: Directory created at: artifacts\\prepare_knn_model]\n",
      "[2024-03-12 02:03:46,837: INFO: common: Directory created at: artifacts\\prepare_knn_model]\n",
      "[2024-03-12 02:03:48,948: INFO: 3961613561: Data loaded successfully from artifacts\\data_ingestion\\raw\\complete_dataset_sample.pkl.]\n",
      "[2024-03-12 02:03:49,271: INFO: 3961613561: Train-test split completed.]\n",
      "Fitting 2 folds for each of 2 candidates, totalling 4 fits\n",
      "[2024-03-12 02:04:53,117: INFO: 3961613561: R^2: 0.9775781232291486]\n",
      "[2024-03-12 02:04:53,136: INFO: 3961613561: RMSE: 3.295134050491929]\n",
      "[2024-03-12 02:04:53,138: INFO: common: Directory created at: artifacts\\prepare_knn_model]\n",
      "[2024-03-12 02:04:53,314: INFO: 3961613561: Best KNN model saved to artifacts\\prepare_knn_model\\knn_model.h5]\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    config_manager = ConfigurationManager(config_filepath=CONFIG_FILE_PATH, params_filepath=PARAMS_FILE_PATH)  # Ensure CONFIG_FILE_PATH and PARAMS_FILE_PATH are correctly defined\n",
    "    prepare_data = KnnModelTrain(config_manager)  # Passing config_manager correctly\n",
    "\n",
    "    prepare_data.load_data()\n",
    "    prepare_data.prepare_pipeline()\n",
    "    prepare_data.train_test_split()\n",
    "    prepare_data.train_and_evaluate()\n",
    "    prepare_data.save_model()\n",
    "    # Any additional methods\n",
    "except Exception as e:\n",
    "    logger.error(f\"Failed to prepare data and model due to: {e}\", exc_info=True)\n",
    "    raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
